<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hadoop HA(高可用)搭建</title>
      <link href="/2019/10/03/Hadoop-HA-%E9%AB%98%E5%8F%AF%E7%94%A8-%E6%90%AD%E5%BB%BA/"/>
      <url>/2019/10/03/Hadoop-HA-%E9%AB%98%E5%8F%AF%E7%94%A8-%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop-HA-高可用-搭建"><a href="#Hadoop-HA-高可用-搭建" class="headerlink" title="Hadoop HA(高可用)搭建"></a>Hadoop HA(高可用)搭建</h1><h2 id="环境准备和集群规划"><a href="#环境准备和集群规划" class="headerlink" title="环境准备和集群规划"></a>环境准备和集群规划</h2><h3 id="1-环境"><a href="#1-环境" class="headerlink" title="1. 环境"></a>1. 环境</h3><p>需要准备三台centos 7虚拟机，配置好下面条件</p><ol><li>设置好hostname主机名(master,slave1,slave2)</li><li>网络可以互相ping通</li><li>关闭防火墙</li></ol><p>如果是用Docker 搭建,使用里面的centos:7镜像的话,还需要用yum安装下面的东西(因为默认没有安装)</p><ol><li>安装好网络工具ss 和ifconfig</li><li>安装sshd服务</li></ol><p>宿主机使用ssh工具连接到三台主机,和对应的上传文件工具(上传安装到到集群)</p><p>这里宿主机是Ubuntu 系统的,直接使用内置的终端ssh连接到集群(Docker的可以直接exec进入bash也行)</p><h3 id="2-集群规划"><a href="#2-集群规划" class="headerlink" title="2. 集群规划"></a>2. 集群规划</h3><table><thead><tr><th>软件</th><th>版本</th><th></th></tr></thead><tbody><tr><td>hadoop</td><td>2.7.7</td><td></td></tr><tr><td>jdk</td><td>1.8</td><td></td></tr><tr><td>系统</td><td>CentOS 7</td><td></td></tr></tbody></table><p>一台master+两台slave</p><table><thead><tr><th>主机名</th><th>角色</th><th>其他</th></tr></thead><tbody><tr><td>master</td><td>namenode</td><td></td></tr><tr><td>slave1</td><td>datanode</td><td></td></tr><tr><td>slave2</td><td>datanode</td><td></td></tr></tbody></table><p>集群软件目录:</p><table><thead><tr><th>项目</th><th>安装目录</th><th></th></tr></thead><tbody><tr><td>hadoop组件等</td><td>/opt/</td><td></td></tr><tr><td>hadoop 数据目录</td><td>/opt/data/</td><td></td></tr><tr><td></td><td></td><td></td></tr></tbody></table><h3 id="3-下载连接"><a href="#3-下载连接" class="headerlink" title="3. 下载连接"></a>3. 下载连接</h3><p>hadoop等:apache 镜像站:<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/apache/</a></p><h2 id="搭建过程"><a href="#搭建过程" class="headerlink" title="搭建过程"></a>搭建过程</h2><h4 id="1-配置-ssh-免密登陆"><a href="#1-配置-ssh-免密登陆" class="headerlink" title="1. 配置 ssh 免密登陆"></a>1. 配置 ssh 免密登陆</h4><blockquote><p>设置主机之间可以免密码登录</p></blockquote><p>两种方式设置免密登陆,一种是手动将公钥追加到要登录的主机的~/.ssh/authorized_keys文件下，一种是使用ssh-copy-id命令(推荐)</p><a id="more"></a><p>​    a. 手动设置免密登陆</p><p>​    手动设置免密登录,这里以设置master免密登录两个slave(和自己)为例</p><ul><li><p>先在master 生成公钥和私钥</p><p>输入<code>ssh-keygen</code> 命令,一直回车,生成的密钥保存在/root/.ssh目录</p></li><li><p>添加公钥到slave1和slave2节点</p><p>master,slave1和slave2节点默认没有<del>/.ssh文件夹,在两个节点执行<code>ssh localhost</code>就会生成</del>/.ssh文件夹(或者手动建立)</p></li><li><p>将master的公钥(id_rsa.pub)添加到 三台主机的~/.ssh/authorized_keys 文件</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">在master执行复制命令</span><br><span class="line"></span><br><span class="line">//复制公钥到slave1节点的/root目录</span><br><span class="line">[root@3de59086e794 ~]# scp ~/.ssh/id_rsa.pub  root@slave1:/root/</span><br><span class="line">The authenticity of host 'slave1 (172.19.0.3)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:JKinnsafdpyJ4e9NB3nvdNz5sHASU0whnVLWL9nyGlg.</span><br><span class="line">ECDSA key fingerprint is MD5:07:b5:34:4e:14:63:2c:3a:8a:52:88:4c:bf:07:58:71.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added 'slave1,172.19.0.3' (ECDSA) to the list of known hosts.</span><br><span class="line">root@slave1's password: </span><br><span class="line">id_rsa.pub                                                                                                  100%  399     1.8MB/s   00:00    </span><br><span class="line">//复制公钥到slave2节点的/root目录</span><br><span class="line">[root@3de59086e794 ~]# scp ~/.ssh/id_rsa.pub  root@slave2:/root/</span><br><span class="line">root@slave2's password: </span><br><span class="line">id_rsa.pub                                                                                                  100%  399     1.2MB/s   00:00    </span><br><span class="line">[root@3de59086e794 ~]#</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">在master,slave1 和 slave2 节点执行(这里为读取id_ras.pub文件的内容追加到authorized_keys文件)</span><br><span class="line"></span><br><span class="line"> cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line"> //查看下添加后的authorized_keys文件</span><br><span class="line">[root@8569789b1bc0 ~]# cat ~/.ssh/authorized_keys </span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCkG4760Jb3jf8ARJ6knvVkXpixJ0lEhyu2GfFDEGF9SYtdtK6/rZ33noGCoK50PmZCIOrVcvYrVit5NyiyWtcQljkwowLPP6K2SRLkh7nCTEHZjfOhyW1qjyteHazKpF36iDli37zcKFzsIQz2IfoaNoyghE3y6eqXsaByO3kooPJlhjvRsb/AbuPDIMgZPeQ++gfEsBALBhfqo4xnQDvCuo8Ibi5Pw9gSs2Kik8JXmxju1R6IHmzQYnhXQy2pVfrvIgyznfWrWRxAPd9xNfTfnZ51hSc0t1Gfnpgi1ptknTfXqm0DYa+TFWzgle98SjZ58plf1Ca9vzWmfc5qJfld root@3de59086e794</span><br><span class="line"></span><br><span class="line">authorized_keys文件的权限,权限需要设置为600 </span><br><span class="line">[root@8569789b1bc0 ~]# ll ~/.ssh/authorized_keys </span><br><span class="line">-rw-r--r-- 1 root root 399 Oct  2 03:17 /root/.ssh/authorized_keys</span><br><span class="line">[root@8569789b1bc0 ~]# </span><br><span class="line">可以看到上面的权限是 644,需要修改为 600(测试 644也能登录,但777不行)</span><br><span class="line">修改为 600的命令为</span><br><span class="line">chmod 600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></li></ul><p>  b. 使用ssh-copyid命令</p><p>  用这个命令就不用复制公钥再追加到文件，直接一个命令就行，以slave1免密登录三台主机为例</p><ul><li><p>生成公钥和私钥</p><p><code>ssh-keygen</code></p></li><li><p>发送公钥到其他节点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id master</span><br><span class="line">ssh-copy-id slave1</span><br><span class="line">ssh-copy-id slave2</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">测试免密登录</span><br><span class="line">ssh master(第一次可能要验证主机,输入yes就行)</span><br><span class="line">直接登录，不用输入密码</span><br></pre></td></tr></table></figure><p><img src="1569986981320.png" alt="1569986981320"></p></li></ul><h4 id="2-安装jdk和hadoop"><a href="#2-安装jdk和hadoop" class="headerlink" title="2. 安装jdk和hadoop"></a>2. 安装jdk和hadoop</h4><blockquote><p>用scp 或者 第三方工具将jdk和hadoop的安装包上传到主机里</p><p>先在master 解压和修改好配置 文件,然后直接发送到其他两个slave主机</p></blockquote><ul><li>解压</li></ul><p>jdk解压</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-8u191-linux-x64.tar.gz  -C /opt/</span><br><span class="line">mv /opt/jdk1.8.0_191/ /opt/jdk1.8</span><br></pre></td></tr></table></figure><p>hadoop解压</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.7.tar.gz -C  /opt/</span><br><span class="line"></span><br><span class="line">mv /opt/hadoop-2.7.7/ /opt/hadoop</span><br></pre></td></tr></table></figure><ul><li>修改配置文件</li></ul><p>配置文件位于hadoop安装目录下的<code>etc/hadoop/</code>文件夹下</p><ol><li><p>hadoop-evn.sh</p><p>这个文件只要修改JAVA_HOME变量</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line"># The java implementation to use.</span><br><span class="line">export JAVA_HOME=/opt/jdk1.8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><ol start="2"><li><p>core-site.xml</p><p>配置文件里出现的cluster1 为fs.default.FS里指定的namenode的地址,如果修改了<code>fs.default.FS</code>,其他的地方也要对应修改</p></li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- cluster1 为集群的 名字--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.cluster1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://cluster1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:2181,slave1:2181,slave2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    临时目录,如果没有指定namenode或者datanode的数据目录，默认会在$&#123;hadoop.tmp.dir&#125;目录下,这个目录默认在???,重启可能会被清除，这里换成指定的hadoop.tmp.dir</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop_tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="3"><li>hdfs-site.xml</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--   --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.cluster1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.cluster1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.cluster1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>slave1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.cluster1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.cluster1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>slave1:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://master:8485;slave1:8485;slave2:8485/cluster1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence</span><br><span class="line">shell(/bin/true)<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/data/hadoop_data/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/data/hadoop_data/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="3"><li>yarn-site.xml</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>运行在nodemanager上的附属服务<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:2181,slave1:2181,slave2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>是否启用HA，默认false<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>最少2个<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>slave1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn-ha<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>集群HA的id，用于在ZooKeeper上创建节点，区分使用</span><br><span class="line"></span><br><span class="line">同一个ZooKeeper集群的不同Hadoop集群<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="4"><li><strong>mapred-site.xml</strong></li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>job web地址<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p>slaves 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure></li></ul><h3 id="zookeeper-安装"><a href="#zookeeper-安装" class="headerlink" title="zookeeper 安装"></a>zookeeper 安装</h3><blockquote><p>高可用需要用到zookeeper</p></blockquote><p>解压</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-3.4.5.tar.gz  -C /opt/</span><br><span class="line">mv /opt/zookeeper-3.4.5/ /opt/zookeeper</span><br></pre></td></tr></table></figure><p>修改zoo.cfg文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> mv conf/zoo_sample.cfg  conf/zoo.cfg</span><br><span class="line">添加修改conf.cfg文件</span><br><span class="line"></span><br><span class="line">dataDir=/opt/data/zookeeper_data</span><br><span class="line"></span><br><span class="line">server.1=master:2888:3888</span><br><span class="line">server.2=slave1:2888:3888</span><br><span class="line">server.3=slave2:2888:3888</span><br></pre></td></tr></table></figure><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>修改的是~/.bash_profile ,每次登录时执行一次，但是 ~/.bashrc每次登录或者打开一个shell时都会执行一次</p><p>这里修<code>.bash_profile</code>文件</p><p><strong>后续，发现启动docker容器登录shell不会执行.bash_profile文件,PATH变量没有配置好的，但会执行<del>/.bashrc,改成修改</del>/.bashrc</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">后面添加下面的变量</span><br><span class="line">export JAVA_HOME=/opt/jdk1.8</span><br><span class="line">export HADOOP_HOME=/opt/hadoop</span><br><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper</span><br><span class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/sbin:$&#123;ZOOKEEPER_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure><p>在三台主机 建立要手动建立的文件夹(namenode数据目录,datanode数据目录,zookeeper的数据目录)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">mkdir -p /opt/data/hadoop_data/datanode</span><br><span class="line">mkdir -p /opt/data/hadoop_data/namenode</span><br><span class="line">zookeeper 数据目录</span><br><span class="line">mkdir -p /opt/data/zookeeper_data</span><br></pre></td></tr></table></figure><p>复制下面的数据到其他节点,第一次可以 直接将整个/opt/下的复制过去，因为组件和上面建的文件夹都在/opt下面</p><ul><li><p>复制环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp /root/.bash_profile root@slave1:/root/</span><br><span class="line">scp /root/.bash_profile root@slave2:/root/</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>复制组件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r  /opt/* root@slave1:/opt/</span><br><span class="line">scp -r  /opt/* root@slave2:/opt/</span><br></pre></td></tr></table></figure></li></ul><p>测试环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@d7998eb32bfb ~]# source /root/.bash_profile</span><br><span class="line">[root@d7998eb32bfb ~]# java -version</span><br><span class="line">java version &quot;1.8.0_191&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_191-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)</span><br><span class="line">[root@d7998eb32bfb ~]#</span><br></pre></td></tr></table></figure><h3 id="修改需要单独配置的文件"><a href="#修改需要单独配置的文件" class="headerlink" title="修改需要单独配置的文件"></a>修改需要单独配置的文件</h3><ul><li>zookeeper 的 myid文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">master,slave1,slave2分别执行</span><br><span class="line">echo 1 &gt; /opt/data/zookeeper_data/myid</span><br><span class="line">echo 2 &gt; /opt/data/zookeeper_data/myid</span><br><span class="line">echo 3 &gt; /opt/data/zookeeper_data/myid</span><br></pre></td></tr></table></figure><h3 id="初始化hadoop"><a href="#初始化hadoop" class="headerlink" title="初始化hadoop"></a>初始化hadoop</h3><ol><li><p>三个主机都启动zookeeper</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><p>使用<code>zkServer.sh status</code>查看身份，如果有一个leader和两个follower就成功</p><p><img src="1569990314156.png" alt="1569990314156"></p><p><img src="1569990323756.png" alt="1569990323756"></p></li></ol><p><img src="1569990305940.png" alt="1569990305940"></p><ol start="2"><li>启动journal node 进程</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">三台机器</span><br><span class="line">hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure><ol start="3"><li>格式化zookeeper节点</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">格式化前查看(通过zkCli.sh进入)</span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] ls /</span><br><span class="line">[zookeeper]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 2]</span><br></pre></td></tr></table></figure><p><code>hdfs zkfc -formatZK</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:java.library.path=/opt/hadoop/lib/native</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:java.compiler=&lt;NA&gt;</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:os.name=Linux</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:os.arch=amd64</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:os.version=5.0.0-29-generic</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:user.name=root</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:user.home=/root</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Client environment:user.dir=/opt</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=master:2181,slave1:2181,slave2:2181 sessionTimeout=5000 watcher=org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef@37afeb11</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ClientCnxn: Opening socket connection to server 3de59086e794/172.19.0.4:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ClientCnxn: Socket connection established to 3de59086e794/172.19.0.4:2181, initiating session</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ClientCnxn: Session establishment complete on server 3de59086e794/172.19.0.4:2181, sessionid = 0x16d8ab6613c0001, negotiated timeout = 5000</span><br><span class="line">19/10/02 04:34:50 INFO ha.ActiveStandbyElector: Session connected.</span><br><span class="line">19/10/02 04:34:50 INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/cluster1 in ZK.</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ZooKeeper: Session: 0x16d8ab6613c0001 closed</span><br><span class="line">19/10/02 04:34:50 INFO zookeeper.ClientCnxn: EventThread shut down</span><br><span class="line">[root@3de59086e794 opt]#</span><br></pre></td></tr></table></figure><ol start="4"><li>格式化namenode节点</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">master上执行</span><br><span class="line">hdfs namenode -format</span><br><span class="line">格式化完后有文件了namenode的目录</span><br><span class="line">[root@3de59086e794 opt]# ll data/hadoop_data/namenode/current/</span><br><span class="line">total 16</span><br><span class="line">-rw-r--r-- 1 root root 201 Oct  2 04:38 VERSION</span><br><span class="line">-rw-r--r-- 1 root root 321 Oct  2 04:38 fsimage_0000000000000000000</span><br><span class="line">-rw-r--r-- 1 root root  62 Oct  2 04:38 fsimage_0000000000000000000.md5</span><br><span class="line">-rw-r--r-- 1 root root   2 Oct  2 04:38 seen_txid</span><br><span class="line">[root@3de59086e794 opt]#</span><br></pre></td></tr></table></figure><p>master上的namenode格式化后，先启动master上的namenode节点(下面同步需要，不然会报错说连接不到master:9000)</p><p><code>hadoop-daemon.sh  start namenode</code></p><p>接下来要在第二个namenode上把master上格式化完的数据同步到第二个namenode上,在slave1(备用namenode节点)上执行</p><p><code>hdfs namenode -bootstrapStandby</code></p><hr><h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><ol><li><p>启动zookeeper(三台主机)</p><p><code>zkServer.sh start</code></p></li><li><p>启动hdfs</p><p><code>start-dfs.sh</code></p></li><li><p>启动yarn</p><p><code>start-yarn.sh</code></p></li></ol><p>4.手动启动yarn的备用节点</p><p><code>yarn-daemon.sh start resourcemanager</code></p><ol start="5"><li>在master启动mr 历史进程</li></ol><p><code>mr-jobhistory-daemon.sh start historyserver</code></p><p>开启jobhistory ,可以在任务结束后查看任务运行情况</p><p>jobhistory 的web端口在mapred-site.xml里设置,为19888</p><h3 id="查看进程"><a href="#查看进程" class="headerlink" title="查看进程"></a>查看进程</h3><p>master</p><p><img src="1569992007816.png" alt="1569992007816"></p><p>slave1</p><p><img src="1569992018604.png" alt="1569992018604"></p><p>slave2</p><p><img src="1569992027208.png" alt="1569992027208"></p><p>查看开放端口</p><p><img src="1570063825179.png" alt="1570063825179"></p><h3 id="停止集群"><a href="#停止集群" class="headerlink" title="停止集群"></a>停止集群</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stop-dfs.sh</span><br><span class="line">stop-yarn.sh</span><br></pre></td></tr></table></figure><h2 id="集群测试"><a href="#集群测试" class="headerlink" title="集群测试"></a>集群测试</h2><h3 id="1-web界面查看"><a href="#1-web界面查看" class="headerlink" title="1. web界面查看"></a>1. web界面查看</h3><p>namenode</p><p><img src="1569992108322.png" alt="1569992108322"></p><p>备用节点slave1</p><p><img src="1569992161841.png" alt="1569992161841"></p><p>​    ResouceManager 主备节点</p><p><img src="1570064382082.png" alt="1570064382082"></p><p>进入备用的会重定向到master的,由于宿主机没有设置master对应的ip,所以访问不了</p><p><img src="1570064476894.png" alt="1570064476894"></p><h3 id="2-namenode-高可用测试"><a href="#2-namenode-高可用测试" class="headerlink" title="2. namenode 高可用测试"></a>2. namenode 高可用测试</h3><blockquote><ol><li>杀掉master上的namenode,查看slave1上的namenode的状态</li><li>启动杀死的namenode,查看它的状态</li></ol></blockquote><p>集群刚启动的情况, 现在master是standby,slave1是active </p><p><img src="1570063926217.png" alt="1570063926217"></p><p><img src="1570063935599.png" alt="1570063935599"></p><p>杀死active的namenode,在slave1上执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">通过jps命令查看到namenode的pid,使用kill -9 pid命令杀死</span><br><span class="line">[root@slave1 /]# jps</span><br><span class="line">51 QuorumPeerMain</span><br><span class="line">372 DFSZKFailoverController</span><br><span class="line">117 NameNode</span><br><span class="line">262 JournalNode</span><br><span class="line">536 NodeManager</span><br><span class="line">185 DataNode</span><br><span class="line">697 Jps</span><br><span class="line">namenode的pid是117</span><br><span class="line">[root@slave1 /]# kill -9 117</span><br><span class="line">杀死后再看jps已经没有了</span><br><span class="line">[root@slave1 /]# jps</span><br><span class="line">51 QuorumPeerMain</span><br><span class="line">372 DFSZKFailoverController</span><br><span class="line">262 JournalNode</span><br><span class="line">536 NodeManager</span><br><span class="line">712 Jps</span><br><span class="line">185 DataNode</span><br><span class="line">[root@slave1 /]#</span><br></pre></td></tr></table></figure><p>这时查看web 界面,master由standby变成active</p><p><img src="1570064080387.png" alt="1570064080387"></p><p>因为namenode进程被杀死,web服务也没了，slave1的打不开</p><p><img src="1570064129505.png" alt="1570064129505"></p><p>然后重新启动被杀死的namenode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">启动namenode进程</span><br><span class="line">[root@slave1 /]# hadoop-daemon.sh start namenode</span><br><span class="line">starting namenode, logging to /opt/hadoop/logs/hadoop--namenode-slave1.out</span><br><span class="line">[root@slave1 /]# jps</span><br><span class="line">51 QuorumPeerMain</span><br><span class="line">836 Jps</span><br><span class="line">372 DFSZKFailoverController</span><br><span class="line">262 JournalNode</span><br><span class="line">742 NameNode</span><br><span class="line">536 NodeManager</span><br><span class="line">185 DataNode</span><br><span class="line">[root@slave1 /]#</span><br></pre></td></tr></table></figure><p>web界面恢复，由active变成现在的standby</p><p><img src="1570064227489.png" alt="1570064227489"></p><h3 id="3-mapreduce-运行测试"><a href="#3-mapreduce-运行测试" class="headerlink" title="3. mapreduce 运行测试"></a>3. mapreduce 运行测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# hadoop jar wordcount.jar WordCount</span><br><span class="line">19/10/03 01:21:40 INFO input.FileInputFormat: Total input paths to process : 1</span><br><span class="line">19/10/03 01:21:41 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">19/10/03 01:21:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1570063799017_0001</span><br><span class="line">19/10/03 01:21:42 INFO impl.YarnClientImpl: Submitted application application_1570063799017_0001</span><br><span class="line">19/10/03 01:21:42 INFO mapreduce.Job: The url to track the job: http://master:8088/proxy/application_1570063799017_0001/</span><br><span class="line">19/10/03 01:21:42 INFO mapreduce.Job: Running job: job_1570063799017_0001</span><br><span class="line">19/10/03 01:21:51 INFO mapreduce.Job: Job job_1570063799017_0001 running in uber mode : false</span><br><span class="line">19/10/03 01:21:51 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">19/10/03 01:21:59 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">19/10/03 01:22:05 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">19/10/03 01:22:07 INFO mapreduce.Job: Job job_1570063799017_0001 completed successfully</span><br><span class="line">19/10/03 01:22:07 INFO mapreduce.Job: Counters: 49</span><br><span class="line">File System Counters</span><br><span class="line">FILE: Number of bytes read=1731</span><br><span class="line">FILE: Number of bytes written=253541</span><br><span class="line">FILE: Number of read operations=0</span><br><span class="line">FILE: Number of large read operations=0</span><br><span class="line">FILE: Number of write operations=0</span><br><span class="line">HDFS: Number of bytes read=1259</span><br><span class="line">HDFS: Number of bytes written=1063</span><br><span class="line">HDFS: Number of read operations=6</span><br><span class="line">HDFS: Number of large read operations=0</span><br><span class="line">HDFS: Number of write operations=2</span><br><span class="line">Job Counters </span><br><span class="line">Launched map tasks=1</span><br><span class="line">Launched reduce tasks=1</span><br><span class="line">Data-local map tasks=1</span><br><span class="line">Total time spent by all maps in occupied slots (ms)=4626</span><br><span class="line">Total time spent by all reduces in occupied slots (ms)=3956</span><br><span class="line">Total time spent by all map tasks (ms)=4626</span><br><span class="line">Total time spent by all reduce tasks (ms)=3956</span><br><span class="line">Total vcore-milliseconds taken by all map tasks=4626</span><br><span class="line">Total vcore-milliseconds taken by all reduce tasks=3956</span><br><span class="line">Total megabyte-milliseconds taken by all map tasks=4737024</span><br><span class="line">Total megabyte-milliseconds taken by all reduce tasks=4050944</span><br><span class="line">Map-Reduce Framework</span><br><span class="line">Map input records=45</span><br><span class="line">Map output records=114</span><br><span class="line">Map output bytes=1497</span><br><span class="line">Map output materialized bytes=1731</span><br><span class="line">Input split bytes=87</span><br><span class="line">Combine input records=0</span><br><span class="line">Combine output records=0</span><br><span class="line">Reduce input groups=89</span><br><span class="line">Reduce shuffle bytes=1731</span><br><span class="line">Reduce input records=114</span><br><span class="line">Reduce output records=89</span><br><span class="line">Spilled Records=228</span><br><span class="line">Shuffled Maps =1</span><br><span class="line">Failed Shuffles=0</span><br><span class="line">Merged Map outputs=1</span><br><span class="line">GC time elapsed (ms)=116</span><br><span class="line">CPU time spent (ms)=1830</span><br><span class="line">Physical memory (bytes) snapshot=432754688</span><br><span class="line">Virtual memory (bytes) snapshot=3911442432</span><br><span class="line">Total committed heap usage (bytes)=348127232</span><br><span class="line">Shuffle Errors</span><br><span class="line">BAD_ID=0</span><br><span class="line">CONNECTION=0</span><br><span class="line">IO_ERROR=0</span><br><span class="line">WRONG_LENGTH=0</span><br><span class="line">WRONG_MAP=0</span><br><span class="line">WRONG_REDUCE=0</span><br><span class="line">File Input Format Counters </span><br><span class="line">Bytes Read=1172</span><br><span class="line">File Output Format Counters </span><br><span class="line">Bytes Written=1063</span><br><span class="line">[root@master ~]#</span><br></pre></td></tr></table></figure><p>查看job history </p><p><img src="1570065773875.png" alt="1570065773875"></p><p><img src="1570065796139.png" alt="1570065796139"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> hadoop </tag>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matplotlib设置显示中文</title>
      <link href="/2019/09/28/Matplotlib%E8%AE%BE%E7%BD%AE%E6%98%BE%E7%A4%BA%E4%B8%AD%E6%96%87/"/>
      <url>/2019/09/28/Matplotlib%E8%AE%BE%E7%BD%AE%E6%98%BE%E7%A4%BA%E4%B8%AD%E6%96%87/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Vuejs待定</title>
      <link href="/2019/09/26/Vuejs%E5%BE%85%E5%AE%9A/"/>
      <url>/2019/09/26/Vuejs%E5%BE%85%E5%AE%9A/</url>
      
        <content type="html"><![CDATA[<ol><li>使用vuecli 创建工程</li></ol><ul><li>命令行方式<br>vue create xxx</li><li>ui 方式<br>启动ui界面 vue ui</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Scrapy手册</title>
      <link href="/2019/09/24/Scrapy%E6%89%8B%E5%86%8C/"/>
      <url>/2019/09/24/Scrapy%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<h3 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h3><ul><li><p>genspider</p><p>使用预定义的模板生成一个spider类</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Usage</span><br><span class="line">=====</span><br><span class="line">  scrapy genspider [options] &lt;name&gt; &lt;domain&gt;</span><br><span class="line"></span><br><span class="line">Generate new spider using pre-defined templates</span><br><span class="line"></span><br><span class="line">Options</span><br><span class="line">=======</span><br><span class="line">--help, -h              show this help message and exit </span><br><span class="line">--list, -l              List available templates  列出可用的模板</span><br><span class="line">--edit, -e              Edit spider after creating it创建spider后编辑它</span><br><span class="line">--dump=TEMPLATE, -d TEMPLATE</span><br><span class="line">                        Dump template to standard output输出模板到标准输出</span><br><span class="line">--template=TEMPLATE, -t TEMPLATE</span><br><span class="line">                        Uses a custom template.</span><br><span class="line">--force                 If the spider already exists, overwrite it with the</span><br><span class="line">                        template 如果spider存在,就强制使用模板覆盖</span><br><span class="line"></span><br><span class="line">Global Options全局选项A</span><br><span class="line">--------------</span><br><span class="line">--logfile=FILE          log file. if omitted stderr will be used日志文件</span><br><span class="line">--loglevel=LEVEL, -L LEVEL</span><br><span class="line">                        log level (default: DEBUG)日志登记</span><br><span class="line">--nolog                 disable logging completely</span><br><span class="line">--profile=FILE          write python cProfile stats to FILE</span><br><span class="line">--pidfile=FILE          write process ID to FILE</span><br><span class="line">--set=NAME=VALUE, -s NAME=VALUE</span><br><span class="line">                        set/override setting (may be repeated)覆盖setting的值</span><br><span class="line">--pdb                   enable pdb on failure失败时开启pdb</span><br></pre></td></tr></table></figure><p>内置的模板有</p><p>  basic<br>  crawl<br>  csvfeed<br>  xmlfeed</p><p>这几个</p></li><li></li></ul><h3 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h3><ul><li><p>在IDE里设置response的类型,来代码提示</p><p>回调函数里的ide识别不了类型，手动指定类型即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scrapy.http.response.html.HtmlResponse</span><br><span class="line"><span class="keyword">from</span> scrapy.http.response.html <span class="keyword">import</span> HtmlResponse</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>设置运行日志输出等级</p><p>调试完后正式运行，不想输出太多日志</p></li></ul><h3 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h3><ol><li><p>创建工程</p></li><li><p>关闭机器人协议</p></li><li><p>生成spider,生成一个叫wallpaper的spider,域名为<code>wall.alphacoders.com</code></p><p>``</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 手册 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flask手册</title>
      <link href="/2019/09/23/Flask%E6%89%8B%E5%86%8C/"/>
      <url>/2019/09/23/Flask%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<p>最新版本为1.1</p><h3 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h3><ul><li><p>微软 vscode 的 Flask 教程</p><p><a href="https://code.visualstudio.com/docs/python/tutorial-flask?WT.mc_id=python-c9-niner#_prerequisites" target="_blank" rel="noopener">https://code.visualstudio.com/docs/python/tutorial-flask?WT.mc_id=python-c9-niner#_prerequisites</a></p></li><li><p>Flask 官方文档</p><p><a href="https://flask.palletsprojects.com/en/1.1.x/" target="_blank" rel="noopener">https://flask.palletsprojects.com/en/1.1.x/</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 手册 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flask </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对象关系教程(Object Relational Tutorial)</title>
      <link href="/2019/09/21/%E5%AF%B9%E8%B1%A1%E5%85%B3%E7%B3%BB%E6%95%99%E7%A8%8B-Object-Relational-Tutorial/"/>
      <url>/2019/09/21/%E5%AF%B9%E8%B1%A1%E5%85%B3%E7%B3%BB%E6%95%99%E7%A8%8B-Object-Relational-Tutorial/</url>
      
        <content type="html"><![CDATA[<p>SQLAlchemy Object Relational Mapper 提出了一个将用户自定义Python类和数据库表，类实例和对应的表里的行结合起来-的方法，包含一个同步在对象和相关的行的状态的所有改变的系统,叫做<code>unit of work</code>,以及一个通过用户定义的类来表达数据库查询和定义相互的关系的系统.</p><p>ORM 对于SQLAlchemy Expression Language 是结构化的.然而SQLAlchemy Expression Language ,在 SQLAlchemy Tutorial 里介绍的,提出了一个直接表达关系型数据库原始结构的系统,ORM 提出了一个高等级的,抽象的使用方式,它自己就是Expression Language的applyied usage的一个例子.</p><p>尽管在ROM和Expression Language的用法上有一些重叠,但相似之处比他们一开始显现的要肤浅.</p><p>用户自定义的domain model(领域模型)</p><p>一个成功的应用可能仅仅使用Object Relation Mapper .在高级的场合,一个由ORM构成的应用偶尔的在指定数据库交互适当的地方使用Expression Language ,</p>]]></content>
      
      
      <categories>
          
          <category> 翻译 </category>
          
          <category> SQLAlchemy官方文档 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Docker手册</title>
      <link href="/2019/09/21/Docker%E6%89%8B%E5%86%8C/"/>
      <url>/2019/09/21/Docker%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<h3 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h3><h4 id="进入容器命令行"><a href="#进入容器命令行" class="headerlink" title="进入容器命令行"></a>进入容器命令行</h4><p><code>docker exec -it dockertest  bash</code></p><h4 id="获取容器IP地址"><a href="#获取容器IP地址" class="headerlink" title="获取容器IP地址"></a>获取容器IP地址</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect --format=&apos;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos;  dockertest</span><br></pre></td></tr></table></figure><p>本机上传文件到docker 容器里</p><p><code>docker cp 本地目录 容器ID:容器内目录</code></p><h3 id="Image-镜像"><a href="#Image-镜像" class="headerlink" title="Image 镜像"></a>Image 镜像</h3><h4 id="查看所有的镜像"><a href="#查看所有的镜像" class="headerlink" title="查看所有的镜像"></a>查看所有的镜像</h4><p>docker images</p><h4 id="搜索镜像"><a href="#搜索镜像" class="headerlink" title="搜索镜像"></a>搜索镜像</h4><p>docker search 关键字</p><a id="more"></a><h3 id="Network-网络"><a href="#Network-网络" class="headerlink" title="Network 网络"></a>Network 网络</h3><h4 id="查看所有网络"><a href="#查看所有网络" class="headerlink" title="查看所有网络"></a>查看所有网络</h4><p><code>docker network ls</code></p><h4 id="创建网络"><a href="#创建网络" class="headerlink" title="创建网络"></a>创建网络</h4><p><code>docker network create -d bridge net_mysql</code></p><h4 id="创建容器时指定网络"><a href="#创建容器时指定网络" class="headerlink" title="创建容器时指定网络"></a>创建容器时指定网络</h4><p><code>--network net_mysql</code></p><h4 id="手动添加容器到网络"><a href="#手动添加容器到网络" class="headerlink" title="手动添加容器到网络"></a>手动添加容器到网络</h4><p><code>docker network connect 网络 容器</code></p><h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><h4 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h4><p><code>docker create [选项] 镜像 [命令][参数]</code></p><ul><li>–name 镜像名字</li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> 手册 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 手册 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker部署MySQL</title>
      <link href="/2019/09/21/Docker%E9%83%A8%E7%BD%B2MySQL/"/>
      <url>/2019/09/21/Docker%E9%83%A8%E7%BD%B2MySQL/</url>
      
        <content type="html"><![CDATA[<p>镜像下载:<br>docker search mysql,pull第一个官方的就行</p><p>支持的tag</p><ul><li>8.0.17, 8.0, 8, latest</li><li>5.7.27, 5.7, 5</li><li>5.6.45, 5.6</li></ul><p>翻译自Docker MySQL官方镜像文档</p><p>原文链接:<a href="https://github.com/docker-library/docs/tree/master/mysql" target="_blank" rel="noopener">https://github.com/docker-library/docs/tree/master/mysql</a></p><p>其他的官方镜像的文档都可以在<a href="https://github.com/docker-library/docs/里找到" target="_blank" rel="noopener">https://github.com/docker-library/docs/里找到</a></p><h3 id="启动mysql服务"><a href="#启动mysql服务" class="headerlink" title="启动mysql服务"></a>启动<code>mysql</code>服务</h3><p>启动MySQL很简单</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">用法:</span><br><span class="line">docker run --name some-mysql   -e MYSQL_ROOT_PASSWORD=root 用户密码 -d mysql:tag </span><br><span class="line">--name 指定容器的名字</span><br><span class="line">-e 指定容器的环境变量</span><br><span class="line">-d 设置容器在后台运行并输出容器id</span><br><span class="line">tag 指定想要的mysql版本,不加默认使用最新</span><br><span class="line"></span><br><span class="line">创建并运行一个叫mysqlserver的mysql容器</span><br><span class="line">docker run --name  mysqlserver  -e MYSQL_ROOT_PASSWORD=123456  -d mysql</span><br><span class="line"></span><br><span class="line">ps 命令看到mysqlserver正在运行</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="从MySQL命令行客户端里连接mysql"><a href="#从MySQL命令行客户端里连接mysql" class="headerlink" title="从MySQL命令行客户端里连接mysql"></a>从MySQL命令行客户端里连接mysql</h3><p>这个镜像不仅可以做上面那个mysql服务端，也可以用来做客户端来连接其他容器里的mysql，或者其他地方的mysql</p><p>上面的启动的容器是mysql服务端,下面的命令可以启动一个作为mysql命令行客户端的容器，并且连接到上面启动的那个容器里的mysql</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">1.  docker  run  -it  --rm mysql mysql -h容器的ip地址 -uexample-user -p</span><br><span class="line">- 查看mysqlserver容器的ip地址</span><br><span class="line">bigdata@ljh-X441UVK:~$ docker inspect --format='&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;'  mysqlserver</span><br><span class="line">172.17.0.2</span><br><span class="line">通过指定ip连接(mysql命令的-h参数)</span><br><span class="line"> docker  run  -it  --rm mysql mysql -h172.17.0.2  -uroot  -p</span><br><span class="line"></span><br><span class="line">2. 通过指定 network连接</span><br><span class="line">可以直接通过容器名字连接，不用输入ip地址</span><br><span class="line">- 创建一个network 网络</span><br><span class="line">```shell</span><br><span class="line">docker network create -d bridge mysqlnet</span><br><span class="line">bigdata@ljh-X441UVK:~$ docker network ls</span><br><span class="line">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class="line">71dfa846b9c6        bridge              bridge              local</span><br><span class="line">9fef614764d3        host                host                local</span><br><span class="line">87bc32c1bc3b        mysqlnet            bridge              local</span><br><span class="line">6d83addc4da3        none                null                local</span><br><span class="line">```</span><br><span class="line">- 将mysqlserver添加到mysqlnet网络里</span><br><span class="line">```shell</span><br><span class="line">docker network connect mysqlnet mysqlserver</span><br><span class="line">```</span><br><span class="line">- mysql客户端命令行 启动时指定mysqlnet网络</span><br><span class="line">启动的容器连接到网络mysqlnet后</span><br><span class="line">运行的命令是 mysql -hmysqlserver  -uroot  -p</span><br><span class="line">mysql -h 指定为mysqlserver这个容器名字，因为mysqlserver在这个网络里,不用写ip地址(可能在同一个网络里有host映射)</span><br><span class="line">docker  run  -it --network mysqlnet --rm mysql mysql -hmysqlserver  -uroot  -p</span><br><span class="line"></span><br><span class="line">3 . 通过--link参数 指定来连接</span><br><span class="line"></span><br><span class="line">docker run -it  --link mysqlserver  --rm mysql  mysql -hmysqlserver -uroot -p</span><br></pre></td></tr></table></figure><p>连接其他的mysql,修改-h对应的即可</p><p>关于MySQL命令行的更多信息请查看:[MySQL documentation][<a href="https://dev.mysql.com/doc/en/mysql.html]" target="_blank" rel="noopener">https://dev.mysql.com/doc/en/mysql.html]</a></p><h3 id="访问容器shell和浏览MySQL日志"><a href="#访问容器shell和浏览MySQL日志" class="headerlink" title="访问容器shell和浏览MySQL日志"></a>访问容器shell和浏览MySQL日志</h3><p><code>docker exec</code>命令可以在Docker容器里运行一个命令.下面这个命令在你的<code>mysql</code>容器里给启动一个交互式的(-it)bash shell</p><p><code>docker exec -it some-mysql bash</code></p><p>可以通过Docker的容器日志查看日志</p><p><code>docker logs some-mysql</code></p><h3 id="使用自定义的MySQL配置文件"><a href="#使用自定义的MySQL配置文件" class="headerlink" title="使用自定义的MySQL配置文件"></a>使用自定义的MySQL配置文件</h3><p>默认的配置文件在<code>/etc/mysql/my.cnf</code>,<code>!includedir</code> 里可能有额外的目录,比如<code>/etc/mysql/conf.d</code>或者<code>/etc/mysql/mysql.conf.d</code>.请在<code>mysql</code>镜像里检查相关文件</p><p>如果<code>/my/custom/config-file.cnf</code>是自定义的配置文件的目录和文件名,可以这样启动<code>mysql</code>容器(注意这个命令里只使用了自定义配置文件的目录的路径)</p><p><code>docker run -name some-mysql -v /my/custom:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag</code></p><p>这个命令会启动一个新的<code>mysql</code>容器,使用<code>/etc/mysql/my.cnf</code>和<code>/etc/mysql/conf.d/config-file.cnf</code>这两个配置文件的合并结果,后面那个的配置文件的配置优先</p><h3 id="不用cnf文件来配置配置"><a href="#不用cnf文件来配置配置" class="headerlink" title="不用cnf文件来配置配置"></a>不用<code>cnf</code>文件来配置配置</h3><p>很多配置选项可以作为标记通过<code>mysqld</code>传递.这样可以很灵活的不用<code>cnf</code>文件来自定义容器.比如,你只想改变默认的编码和Collation字符集 成UTF-8(utf8mb4)，只需运行下面的</p><p><code>docker run -name some-mysql -e  MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8m4 --collation-server=utf8m4_unicode_ci</code></p><p>如果想查看全部可以用的选项，只需要运行:</p><p><code>docker run -it --rm mysql:tag --verbose --help</code></p><h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>当你启动<code>mysql</code>镜像,你可以在<code>docker run</code>命令行里传递一个或者更多环境变量来调整MySQL的配置.注意如果启动的容器有一个已经包含数据库的数据目录,下面的变量将不会有效果:已存在的数据库不会有变化.</p><p>查看这个连接<a href="https://dev.mysql.com/doc/refman/5.7/en/environment-variables.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/environment-variables.html</a> 查看MySQL本身支持的环境变量的文档(特殊的变量像<code>MSQL_HOST</code>,和这个镜像使用的时候会出现问题)</p><p><code>MYSQL_ROOT_PASSWORD</code></p><p>这个变量必须存在,指定的密码将会设置为MySQL<code>root</code>用户的密码.在上面的例子里，他是设置成<code>my-secret-pw</code>.</p><p><code>MYSQL_DATABASE</code></p><p>这个变量是可选的,如果指定了，在镜像启动时会用这个的值创建一个数据库.如果也指定了 user/password (下面),这个用户会被授予这个数据库的超级权限</p><p><code>MYSQL_USER</code>,<code>MYSQL_PASSWORD</code></p><p>这些变量是可选的，结合在一起使用来创建一个新用户和设置用户的密码.这个用户会被授予上面通</p><p>注意这里不需要用这个机制来创建root用户，root用户会用<code>MYSQL_ROOT_PASSWORD</code>变量指定的密码来创建.</p><p><code>MYSQL_ALLOW_EMPTY_PASSWORD</code></p><p>这是个可选的变量.设置<code>yes</code> 就允许root用户用一个空白的密码来启动容器.注意:不推荐设置成<code>yes</code>除非你知道你在干什么,因为这个会让你的MySQL实例完全没有保护,任何人都能获得完整的超级用户权限</p><p><code>MYSQL_RANDOM_ROOT_PASSWORD</code><br>s<br>这是一个可选变量.设置成<code>yes</code>会随机产生一个初始化密码给root用户(使用pwgen).这个生成的密码会输出到标准输出里.</p><p><code>MYSQL_ONETIME_PASSWORD</code></p><p>设置root 用户初始化完后就过期,第一次登录时强制修改密码.注意:这个功能只支持MySQL 5.6+.在MySQL 5.5使用会在初始化时抛出一个错误.</p><hr><p>后面的未认真翻译</p><h3 id="Docker-隐私"><a href="#Docker-隐私" class="headerlink" title="Docker 隐私"></a>Docker 隐私</h3><p>作为通过环境变量来传递敏感信息的代替,<code>_FILE</code>可能是拼接到之前列出的环境变量里,初始化脚本从一个容器的文件里加载这些变量的值,这个可以用从保存在<code>/run/secrets/&lt;secret_name&gt;</code>文件的Docker secrets 加载密码</p><p>比如</p><p><code>docker run -name some-mysql -e MYSQL_ROOT_PASSWORD_FILE=/run/secrets/mysql-root -d mysql:tag</code></p><p>当前只支持<code>MYSQL_ROOT_PASSWORD</code>,<code>MYSQL_ROOT_HOST</code>,<code>MYSQL_DATABASE</code>,<code>MYSQL_USER</code>和<code>MYSQL_PASSWORD</code></p><h3 id="初始化一个新鲜的实例"><a href="#初始化一个新鲜的实例" class="headerlink" title="初始化一个新鲜的实例"></a>初始化一个新鲜的实例</h3><p>当容器第一次启动时,将会创建一个指定名字的数据库和用提供的配置变量来初始化.此外,还会执行在<code>/docker-entrypoint-initdb.d</code>里的<code>.sh</code>,<code>.sql</code>和<code>.sql.gz</code>文件.文件会按照字母排序执行.你可以通过<a href="https://docs.docker.com/engine/tutorials/dockervolumes/#mount-a-host-file-as-a-data-volume" target="_blank" rel="noopener">mounting a SQL dump into that directory</a>和提供一个<a href="https://docs.docker.com/reference/builder/" target="_blank" rel="noopener">custom images</a>带有贡献的数据.SQL 文件会默认导入通过<code>MYSQL_DATABASE</code>变量指定的数据库.</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><h3 id="在哪里保存数据"><a href="#在哪里保存数据" class="headerlink" title="在哪里保存数据"></a>在哪里保存数据</h3><p>重要的提示:这里有几个方式来保存在Docker 容器上运行的应用使用的数据,我们鼓励<code>mysql</code>镜像的用户熟悉下面可用的选项,包括:</p><ul><li>让Docker 管理数据库数据的保存<a href="https://docs.docker.com/engine/tutorials/dockervolumes/#adding-a-data-volume" target="_blank" rel="noopener">通过用他内部的volume management来写入数据库文件到宿主机</a>,这个是默认的，并且对于用户来说很容易和公平透明.缺点是这些文件很难被直接运行在宿主机上的工具和应用定位.i.e outside container</li><li>创建一个数据目录在宿主机上(容器外)，<a href="https://docs.docker.com/engine/tutorials/dockervolumes/#mount-a-host-directory-as-a-data-volume" target="_blank" rel="noopener">在容器里挂载这个目录可见</a>,这样把数据库文件放在宿主机上知道的位置,并且容器宿主机上的工具和应用访问这些文件.缺点是用户需要确定目录存在，和比如权限和其他安全机制配置正确</li></ul><p>Docker 文件是个好起点来理解不同的存储选项和变化,这里有很多blog和论坛帖子讨论和给建议 。简单展示下上面后面选项的基本流程</p><ol><li><p>在宿主系统的合适volume创建一个目录,比如<code>/my/own/datadir</code>.</p></li><li><p>启动<code>mysql</code>容器<br>docker run –name some-mysql -v /my/own/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag</p><p>命令的<code>-v /my/own/datadir:/var/lib/mysql</code>部分,从宿主下挂在<code>/my/own/datadir</code>作为容器里的<code>/var/lib/mysql</code>,那里是MySQL默认的数据文件的地方</p></li></ol><h3 id="直到MySQL初始化完成之前没有连接"><a href="#直到MySQL初始化完成之前没有连接" class="headerlink" title="直到MySQL初始化完成之前没有连接"></a>直到MySQL初始化完成之前没有连接</h3><p>当容器启动时如果没有数据库初始化,将会创建一个默认的数据库.这个是预期的行为,这意味着它将不会接受传入的连接直到初始化完成.这个会在使用自动化工具时有问题,比如<code>docker-compose</code>,这个会同时启动几个容器</p><p>如果你尝试连接MySQL的应用没有处理MySQL 停机或者等待MySQL完美启动,在服务启动前放一个连接重试是必须的.在官方镜像里这样的实现,<a href="https://github.com/docker-library/wordpress/blob/1b48b4bccd7adb0f7ea1431c7b470a40e186f3da/docker-entrypoint.sh#L195-L235" target="_blank" rel="noopener">WordPress</a>或者<a href="https://github.com/docker-library/docs/blob/9660a0cccb87d8db842f33bc0578d769caaf3ba9/bonita/stack.yml#L28-L44" target="_blank" rel="noopener">Bonita</a></p><h3 id="对于已存在的数据库的用法"><a href="#对于已存在的数据库的用法" class="headerlink" title="对于已存在的数据库的用法"></a>对于已存在的数据库的用法</h3><p>如果你启动一个有数据目录的<code>mysql</code>容器,而且存在了一个数据库(specifically,一个<code>mysql</code>子目录),应该从命令行里提交一个<code>$MYSQL_ROOT_PASSWORD</code>变量;他无论如何都会被忽略,并且已存在的数据库不会改变</p><h3 id="以任意的用户运行"><a href="#以任意的用户运行" class="headerlink" title="以任意的用户运行"></a>以任意的用户运行</h3><p>如果你知道你目录的权限已经设置合理(比如对于一个已存在的数据库运行,像上面说的)或者你需要指定mysqld运行的UID/GID.可以用<code>--user</code>来调用镜像设置任何值来完成想要的权限/配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir data</span><br><span class="line">ls -lnd data</span><br><span class="line"> docker run -v &quot;$PWD/data&quot;:/var/lib/mysql --user 1000:1000 --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag</span><br></pre></td></tr></table></figure><h3 id="创建数据库导出"><a href="#创建数据库导出" class="headerlink" title="创建数据库导出"></a>创建数据库导出</h3><p>大多数正常的工具都能用,尽管他们的用法有一点令人费解 在一些场合来确保他们有权限访问<code>mysqld</code>服务.一个简单的方法来确保就是使用<code>docker exec</code>和从相同的容器里运行工具,像下面这样:</p><p><code>docker exec some-mysql sh -c &#39;exec mysqldump --all-databases -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;&#39; &gt; /some/path/on/your/host/all-databases.sql</code></p><h3 id="从导出文件里恢复数据"><a href="#从导出文件里恢复数据" class="headerlink" title="从导出文件里恢复数据"></a>从导出文件里恢复数据</h3><p>对于恢复数据,你可以用<code>-i</code>选项的<code>docker exec</code>命令,像下面这样:</p><p><code>$ docker exec -i some-mysql sh -c &#39;exec mysql -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;&#39; &lt; /some/path/on/your/host/all-databases.sql</code></p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo手册</title>
      <link href="/2019/09/21/Hexo%E6%89%8B%E5%86%8C/"/>
      <url>/2019/09/21/Hexo%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><h4 id="创建文章"><a href="#创建文章" class="headerlink" title="创建文章"></a>创建文章</h4><p><code>hexo new [layout] title</code><br>layout 可以选</p><ul><li>draft<br>草稿</li><li>post<br>post</li><li>page<br>页面</li></ul><h4 id="草稿转为文章"><a href="#草稿转为文章" class="headerlink" title="草稿转为文章"></a>草稿转为文章</h4><p><code>hexo publish [layout] title</code></p><h3 id="文章在首页显示加载更多"><a href="#文章在首页显示加载更多" class="headerlink" title="文章在首页显示加载更多"></a>文章在首页显示加载更多</h3><p>在想要的地方加入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- more --&gt;</span><br></pre></td></tr></table></figure><a id="more"></a>]]></content>
      
      
      <categories>
          
          <category> 手册 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 手册 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HowTo</title>
      <link href="/2019/09/07/HowTo/"/>
      <url>/2019/09/07/HowTo/</url>
      
        <content type="html"><![CDATA[<h2 id="How-to"><a href="#How-to" class="headerlink" title="How to"></a>How to</h2><h3 id="1-怎么用英语询问时间"><a href="#1-怎么用英语询问时间" class="headerlink" title="1. 怎么用英语询问时间"></a>1. 怎么用英语询问时间</h3><ul><li><p>同事或者朋友</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">what time is it?</span><br></pre></td></tr></table></figure></li><li><p>陌生人</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Have you got the time ?</span><br><span class="line">更加礼貌的方式</span><br><span class="line">Execuse me, have you got the time?</span><br><span class="line">Execuse me,have you got the time please?</span><br><span class="line">Sorry,hava you got the time?</span><br><span class="line">Sorry,hava you got the time please?</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>英语四级满分作文模板</title>
      <link href="/2019/08/28/%E8%8B%B1%E8%AF%AD%E5%9B%9B%E7%BA%A7%E6%BB%A1%E5%88%86%E4%BD%9C%E6%96%87%E6%A8%A1%E6%9D%BF/"/>
      <url>/2019/08/28/%E8%8B%B1%E8%AF%AD%E5%9B%9B%E7%BA%A7%E6%BB%A1%E5%88%86%E4%BD%9C%E6%96%87%E6%A8%A1%E6%9D%BF/</url>
      
        <content type="html"><![CDATA[<blockquote><p>来自<a href="http://www.eudic.cn/ting/" target="_blank" rel="noopener">每日英语听力</a>上的专辑</p></blockquote><p><img src="/images/%E5%98%A4glish.gif" alt="Let&#39;s speak 嘤glish"></p><h3 id="08-30-慰问生病的学生"><a href="#08-30-慰问生病的学生" class="headerlink" title="08-30 慰问生病的学生"></a>08-30 慰问生病的学生</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Dear Alice,I am deeply concerned that I did not see you</span><br><span class="line">in  class today.</span><br></pre></td></tr></table></figure><blockquote><p>亲爱的爱丽丝,今天上课没有见到你,我很担心.</p></blockquote><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Later I learned that you stayed at home because of  a  </span><br><span class="line">heavy cold.The weather is quite fickle these days ,and </span><br><span class="line">you should make sure that you  err on the  side of caution </span><br><span class="line">by wearing a bit more .</span><br></pre></td></tr></table></figure><blockquote><p>后来我得知你是因为得了重感冒在家休息。最近天气变化无常,你应该适时增减衣物。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">I think the bed rest is the best medicine for a cold and hope that</span><br><span class="line">you will recover in no time at all.Looking forward to seeing you </span><br><span class="line">agan in class tomorrow.</span><br></pre></td></tr></table></figure><blockquote><p>我想卧床休息是治疗感冒的良药吧,希望你能尽快康复。希望明天上课能见到你。</p></blockquote><ul><li><p>err on the side of caution</p><p>宁可多表现(某种行为)</p><p>再…也不为过</p></li><li><p>make sure that + 从句</p><p>一定要做某事</p></li><li><p>in no time</p><p>立即;很快</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 英语 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>第一篇博客</title>
      <link href="/2019/08/27/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
      <url>/2019/08/27/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<p><img src="1566915832561.png" alt="1566915832561"></p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote><p>滑而不稽则罔，稽而不滑则殆 .</p><p>​                                                           –孔子</p></blockquote><a id="more"></a><h3 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h3><blockquote><p>使用<a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo</a> 搭建的</p><p>互联网上的个人小窝搭建好啦</p><p>本来是想练习Flask+VueJs自己写个小博客网站来练习的(工程已凉),过程中发现了Hexo这个东西,决定用他来做个自己的博客 网站</p></blockquote><p>搭建过程不用敲代码,现在使用的是Hexo 的 NexT主题,还是默认样式.</p><p>在各种姻缘巧合之下，这个暂时不知道写什么文章的博客就暂时搭建好了</p><p>顺便写一篇’入伙’文章….</p><p><img src="1566915861558.png" alt="1566915861558"></p><h3 id="写文章"><a href="#写文章" class="headerlink" title="写文章"></a>写文章</h3><p>现在如果要添加一篇文章的话,要 </p><ul><li>本地用Hexo新建一篇,会生成.md文件</li><li>编辑生成的.md文件,编写</li><li>用Hexo 根据.md文件生成静态网页 </li><li>上传到FTP空间(可以直接使用命令,但是配置ftp时连接不上,现在是手动上传)</li></ul><p>现在还是有些麻烦 ,和些小问题. 今天有看到一个UI的工具,还没试,用那个应该会简单许多.</p><p><img src="1566915925884.png" alt="1566915925884"></p><h2 id="搭建环境"><a href="#搭建环境" class="headerlink" title="搭建环境"></a>搭建环境</h2><h3 id="1-博客框架"><a href="#1-博客框架" class="headerlink" title="1. 博客框架"></a>1. 博客框架</h3><p>使用<a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo</a>来搭建的</p><p><img src="1566911122321.png" alt="1566911122321"></p><h3 id="2-部署主机"><a href="#2-部署主机" class="headerlink" title="2.部署主机"></a>2.部署主机</h3><p>最后将生成的网页部署到 FTP主机 (我的这个就是),或者Github Page,Heroku上</p><p>放到FTP主机上前提得有主机,我用的是之前买的(一直荒废)香港3v主机</p><p>如果是部署到Github那些地方应该就是免费的(还没试过)</p><p><img src="1566911060119.png" alt="1566911060119"></p><h3 id="3-域名"><a href="#3-域名" class="headerlink" title="3.域名"></a>3.域名</h3><p>域名是之前在<a href="https://www.cndns.com" target="_blank" rel="noopener">美橙互联</a>上购买的<code>formatfa.top</code></p><p><img src="1566911264156.png" alt="1566911264156"></p><p><img src="1566911310625.png" alt="1566911310625"></p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>图片文章测试</title>
      <link href="/2019/08/26/%E5%9B%BE%E7%89%87%E6%96%87%E7%AB%A0%E6%B5%8B%E8%AF%95/"/>
      <url>/2019/08/26/%E5%9B%BE%E7%89%87%E6%96%87%E7%AB%A0%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p><img src="1566826762609.png" alt="1566826762609"></p><p><img src="1566826987497.png" alt="1566826987497"></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
